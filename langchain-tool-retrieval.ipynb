{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenBB Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserSettings\n",
       "\n",
       "id: 065686e1-1b3e-7dfa-8000-534067a193fb\n",
       "profile: {'hub_session': {'username': 'didier', 'email': 'didier.lopes@openbb.finance', 'primary_usage': 'personal', 'user_uuid': 'a7ac8796-9328-4fd5-bd12-2c528855655b', 'token_type': 'bearer', 'access_token': SecretStr('**********')}}\n",
       "credentials: {'benzinga_api_key': None, 'fred_api_key': SecretStr('**********'), 'fmp_api_key': SecretStr('**********'), 'tradingeconomics_api_key': None, 'intrinio_api_key': None, 'polygon_api_key': SecretStr('**********')}\n",
       "preferences: {'data_directory': '/Users/didierlopes/OpenBBUserData', 'export_directory': '/Users/didierlopes/OpenBBUserData/exports', 'user_styles_directory': '/Users/didierlopes/OpenBBUserData/styles/user', 'cache_directory': '/Users/didierlopes/OpenBBUserData/cache', 'charting_extension': 'openbb_charting', 'chart_style': 'dark', 'plot_enable_pywry': True, 'plot_pywry_width': 1400, 'plot_pywry_height': 762, 'plot_open_export': False, 'table_style': 'dark', 'request_timeout': 15, 'metadata': True, 'output_type': 'OBBject'}\n",
       "defaults: {'routes': {}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dependencies, in specific langchain\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import hub\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.output_parsers import RetryWithErrorOutputParser\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"  # Avoid some warnings from HuggingFace\n",
    "\n",
    "# Set up OpenAI API key\n",
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# Set up OpenBB Personal Access Token from https://my.openbb.co/app/platform/pat\n",
    "from openbb import obb\n",
    "from utils import map_openbb_collection_to_langchain_tools  # provides access to OpenBB Tools\n",
    "obb.account.login(pat=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OpenBB tools for retrieval\n",
    "\n",
    "The following will return all OpenBB tools that we want our agent to have access. This matches the layout architecture defined by OpenBB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 27 OpenBB tools has been prepared for function calling\n",
      "\n",
      "Processing each OpenBB tool description into a list of docs...\n",
      "\n",
      "Create embeddings for each of these OpenBB tool descriptions...\n"
     ]
    }
   ],
   "source": [
    "# can also give a single string, but since we want our agent to have more context we provide access to more functions\n",
    "# TODO: We can create a \"universal_openbb_tools\" that allows access to all OpenBB functions since we use embeddings\n",
    "# for the description of each, the context size is not an issue. However, with a bigger vector store, the accuracy may\n",
    "# take a hit.\n",
    "openbb_tools = map_openbb_collection_to_langchain_tools(\n",
    "    openbb_commands_root = [\n",
    "        \"/equity/fundamental\",\n",
    "        \"/equity/compare\",\n",
    "        \"/equity/estimates\"\n",
    "    ]\n",
    ")\n",
    "print(f\"A total of {len(openbb_tools)} OpenBB tools has been prepared for function calling\\n\")\n",
    "\n",
    "\n",
    "print(\"Processing each OpenBB tool description into a list of docs...\\n\")\n",
    "# Parse the description (i.e. docstring + output fields) for each of these tools\n",
    "docs = [\n",
    "    Document(page_content=t.description, metadata={\"index\": i})\n",
    "    for i, t in enumerate(openbb_tools)\n",
    "]\n",
    "\n",
    "print(\"Create embeddings for each of these OpenBB tool descriptions...\")\n",
    "# Create embeddings from each of these function descriptions\n",
    "# this will be important for when we want the agent to know what\n",
    "# function to use for a particular query\n",
    "vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
    "\n",
    "# Note: Empirically, sentence embeddings can occasionally be better. But due to prompting\n",
    "# requesting keywords, it has been found that OpenAIEmbeddings leads to better results.\n",
    "# Plus using OpenAI's API is far lighter than relying on Hugging Face's SentenceTransformerEmbeddings\n",
    "# sentence_transformer = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# vector_store = FAISS.from_documents(docs, sentence_transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools(query):\n",
    "    \"Retrieve the most relevant documents to a query.\"\n",
    "    # Set a docs retriever that looks for a score_threshold of 0.65, this means that if the search retrieval\n",
    "    # is confident in a few endpoints we don't rule out any due to a hardcoded number of docs to be retrieved\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={'score_threshold': 0.65}\n",
    "    )\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    # This is a fallback mechanism in case the threshold is too high. In that case, we fall back to getting the\n",
    "    # top 2 results with higher similarity scores and pray that the relevant tool is one of them.\n",
    "    if len(docs) < 2:\n",
    "        retriever = vector_store.as_retriever(\n",
    "            search_kwargs={\"k\": 2}\n",
    "        )\n",
    "        \n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        \n",
    "    return [openbb_tools[d.metadata[\"index\"]] for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools retrieved for 'market cap':\n",
      "  /equity/fundamental/metrics - Key Metrics. Key metrics for a given company.\n",
      "  /equity/fundamental/multiples - Equity Valuation Multiples. Valuation multiples for a stock ticker.\n",
      "  /equity/fundamental/overview - Company Overview. General information about a company.\n",
      "  /equity/fundamental/income - Income Statement. Report on a company's financial performance.\n",
      "\n",
      "Tools retrieved for 'peers':\n",
      "  /equity/compare/peers - Equity Peers. Company peers.\n",
      "  /equity/fundamental/metrics - Key Metrics. Key metrics for a given company.\n"
     ]
    }
   ],
   "source": [
    "print(\"Tools retrieved for 'market cap':\")\n",
    "fetched_tools = get_tools(\"market cap\")\n",
    "for tool in fetched_tools:\n",
    "    print(\"  \" + tool.name + \" - \" + tool.description.split('\\n')[0])\n",
    "\n",
    "print(\"\\nTools retrieved for 'peers':\")\n",
    "fetched_tools = get_tools(\"peers\")\n",
    "for tool in fetched_tools:\n",
    "    print(\"  \" + tool.name + \" - \" + tool.description.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI-powered Financial Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt for our financial analyst\n",
    "# These prompts answer 2 very different scenarios and in this notebook we are going to demonstrate that our OpenBB agent\n",
    "# is capable of handling both efficiently, utilizing the same architecture\n",
    "\n",
    "# This prompt is very deterministic which allows us to access right or wrong immediately because we can check the facts\n",
    "# It also involves a few complex operations such as extracting a list of tickers from an endpoint and iterating through\n",
    "# that list using a different endpoint. Then based on those outputs, a reasoning is made.\n",
    "PROMPT =  \"\"\"\\\n",
    "Check what are TSLA peers. From those, check which one has the highest market cap.\n",
    "Then, on the ticker that has the highest market cap get the most recent price target estimate from an analyst,\n",
    "and tell me who it was and on what date the estimate was made.\n",
    "\"\"\"\n",
    "\n",
    "# This prompt is not deterministic and allows us to leverage LLMs to provide alpha by uncovering insights\n",
    "# that would be hard for a human to discover. Instead of telling the agent what to do, we expect the agent\n",
    "# to provide a reasoning of what it would do to perform a typical analyst task, without guardrails.\n",
    "# PROMPT = \"Perform a fundamentals financial analysis of AMZN using the most recently available data. What do you find that's interesting?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task decomposition\n",
    "\n",
    "1. Break a larger query down into subquery.\n",
    "2. Then for each subquery create a set of keywords that allow you to fetch the right tool to execute that same subquery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic is used to enforce structured output\n",
    "# \"Pydantic is all you need\" - https://www.youtube.com/watch?v=yj-wSRJwrrc\n",
    "\n",
    "class SubQuestion(BaseModel):\n",
    "    \"Defines Pydantic model we want each subquestion to have, including each field and what they represent\"\n",
    "    id: int = Field(\n",
    "        description=\"The unique ID of the subquestion.\"\n",
    "    )\n",
    "    question: str = Field(\n",
    "        description=\"The subquestion itself.\"\n",
    "    )\n",
    "    query: str = Field(\n",
    "        description=\"The query to pass to the `fetch_tools` function to retrieve the appropriate tool to answer the question.\"\n",
    "    )\n",
    "    depends_on: list[int] = Field(\n",
    "        description=\"The list of subquestion ids whose answer is required to answer this subquestion.\",\n",
    "        default=[]\n",
    "    )\n",
    "\n",
    "class SubQuestionList(BaseModel):\n",
    "    \"Defines Pydantic model output we want to enforce, which is a list of the previous SubQuestion Pydantic model\"\n",
    "    subquestions: list[SubQuestion] = Field(\n",
    "        description=\"The list of SubQuestion objects.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_decomposition(task: str):\n",
    "    \"Break a larger query down into subquery. Then for each subquery create a set of keywords that allow you to fetch the right tool to execute that same subquery.\"\n",
    "    subquestion_parser = PydanticOutputParser(pydantic_object=SubQuestionList)\n",
    "    \n",
    "    system_message = \"\"\"\\\n",
    "    You are a world-class state-of-the-art agent.\n",
    "    \n",
    "    You can access multiple tools, via a \"fetch_tools\" function that will retrieve the necessary tools.\n",
    "    The `fetch_tools` function accepts a string of keywords as input specifying the type of tool to retrieve.\n",
    "    Each retrieved tool represents a different data source or API that can retrieve the required data.\n",
    "    \n",
    "    Your purpose is to help answer a complex user question by generating a list of subquestions,\n",
    "    as well as the corresponding keyword query to the \"fetch_tools\" function\n",
    "    to retrieve the relevant tools to answer each corresponding subquestion.\n",
    "    You must also specify the dependencies between subquestions, since sometimes one\n",
    "    subquestion will require the outcome of another in order to fully answer.\n",
    "    \n",
    "    These are the guidelines you consider when completing your task:\n",
    "    * Be as specific as possible\n",
    "    * Avoid using acronyms\n",
    "    * The subquestions should be relevant to the user's question\n",
    "    * The subquestions should be answerable by the tools retrieved by the query to `fetch_tools`\n",
    "    * You can generate multiple subquestions\n",
    "    * You don't need to query for a tool if you don't think it's relevant\n",
    "    * A subquestion may not depend on a subquestion that proceeds it (i.e. comes after it.)\n",
    "    \n",
    "    ## Output format\n",
    "    {format_instructions}\n",
    "    \n",
    "    ### Example responses\n",
    "    ```json\n",
    "    {{\"subquestions\": [\n",
    "        {{\n",
    "            \"id\": 1,\n",
    "            \"question\": \"What are the latest financial statements of AMZN?\", \n",
    "            \"query\": \"financial statements\",\n",
    "            \"depends_on\": []\n",
    "        }}, \n",
    "        {{\n",
    "            \"id\": 2,\n",
    "            \"question\": \"What is the most recent revenue and profit margin of AMZN?\", \n",
    "            \"query\": \"revenue profit margin ratios\",\n",
    "            \"depends_on\": []\n",
    "        }}, \n",
    "        {{\n",
    "            \"id\": 3,\n",
    "            \"question\": \"What is the current price to earnings (P/E) ratio of AMZN?\", \n",
    "            \"query\": \"ratio price to earnings\",\n",
    "            \"depends_on\": []\n",
    "        }}, \n",
    "        {{\n",
    "            \"id\": 4,\n",
    "            \"question\": \"Who are the peers of AMZN?\", \n",
    "            \"query\": \"peers\",\n",
    "            \"depends_on\": []\n",
    "        }},\n",
    "        {{\n",
    "            \"id\": 5,\n",
    "            \"question\": \"Which of AMZN's peers have the largest market cap?\", \n",
    "            \"query\": \"market cap\",\n",
    "            \"depends_on\": [4]\n",
    "        }}\n",
    "    ]}}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    human_message = \"\"\"\\\n",
    "        ## User Question\n",
    "        {input}\n",
    "        \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_message),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(\n",
    "        format_instructions=subquestion_parser.get_format_instructions()\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4\"\n",
    "    )  # gpt-3.5-turbo works well, but gpt-4-1106-preview isn't good at returning JSON.\n",
    "    \n",
    "    subquestion_chain = {\"input\": lambda x: x[\"input\"]} | prompt | llm | subquestion_parser\n",
    "\n",
    "    subquestion_list = subquestion_chain.invoke({\"input\": task})\n",
    "\n",
    "    return subquestion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Who are the peers of Tesla (TSLA)?\n",
      "  Query: peers TSLA\n",
      "2 - Which of Tesla's peers has the highest market cap?\n",
      "  Query: market cap\n",
      "  Depends on: [1]\n",
      "3 - What is the most recent price target estimate for the company with the highest market cap?\n",
      "  Query: price target estimate\n",
      "  Depends on: [2]\n",
      "4 - Who made the most recent price target estimate for the company with the highest market cap?\n",
      "  Query: analyst name\n",
      "  Depends on: [3]\n",
      "5 - On what date was the most recent price target estimate for the company with the highest market cap made?\n",
      "  Query: estimate date\n",
      "  Depends on: [3]\n"
     ]
    }
   ],
   "source": [
    "subquestion_list = task_decomposition(PROMPT)\n",
    "\n",
    "# Shows the result from task decomposition\n",
    "for subquestion in subquestion_list.subquestions:\n",
    "    print(f\"{subquestion.id} - {subquestion.question}\")\n",
    "    print(f\"  Query: {subquestion.query}\")\n",
    "    if subquestion.depends_on:\n",
    "        print(f\"  Depends on: {subquestion.depends_on}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool retrieval\n",
    "\n",
    "Use the previously generated queries in order to fetch the tools necessary to answer the subquestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Who are the peers of Tesla (TSLA)?\n",
      "  Query: peers TSLA\n",
      "  Depends on: []\n",
      "  Fetched tools:\n",
      "    /equity/compare/peers: Equity Peers. Company peers.\n",
      "    /equity/fundamental/multiples: Equity Valuation Multiples. Valuation multiples for a stock ticker.\n",
      "\n",
      "2 - Which of Tesla's peers has the highest market cap?\n",
      "  Query: market cap\n",
      "  Depends on: [1]\n",
      "  Fetched tools:\n",
      "    /equity/fundamental/metrics: Key Metrics. Key metrics for a given company.\n",
      "    /equity/fundamental/multiples: Equity Valuation Multiples. Valuation multiples for a stock ticker.\n",
      "    /equity/fundamental/overview: Company Overview. General information about a company.\n",
      "    /equity/fundamental/income: Income Statement. Report on a company's financial performance.\n",
      "\n",
      "3 - What is the most recent price target estimate for the company with the highest market cap?\n",
      "  Query: price target estimate\n",
      "  Depends on: [2]\n",
      "  Fetched tools:\n",
      "    /equity/estimates/consensus: Price Target Consensus. Price target consensus data.\n",
      "    /equity/estimates/price_target: Price Target. Price target data.\n",
      "    /equity/estimates/historical: Historical Analyst Estimates. Analyst stock recommendations.\n",
      "    /equity/fundamental/multiples: Equity Valuation Multiples. Valuation multiples for a stock ticker.\n",
      "\n",
      "4 - Who made the most recent price target estimate for the company with the highest market cap?\n",
      "  Query: analyst name\n",
      "  Depends on: [3]\n",
      "  Fetched tools:\n",
      "    /equity/estimates/historical: Historical Analyst Estimates. Analyst stock recommendations.\n",
      "    /equity/fundamental/overview: Company Overview. General information about a company.\n",
      "\n",
      "5 - On what date was the most recent price target estimate for the company with the highest market cap made?\n",
      "  Query: estimate date\n",
      "  Depends on: [3]\n",
      "  Fetched tools:\n",
      "    /equity/estimates/historical: Historical Analyst Estimates. Analyst stock recommendations.\n",
      "    /equity/fundamental/historical_eps: Historical earnings-per-share for a given company.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subquestions_and_tools = []\n",
    "for subquestion in subquestion_list.subquestions:\n",
    "    tools = get_tools(subquestion.query)\n",
    "    subquestions_and_tools.append(\n",
    "        {   \"id\": subquestion.id,\n",
    "            \"subquestion\": subquestion.question,\n",
    "            \"query\": subquestion.query,\n",
    "            \"tools\": tools,\n",
    "            \"depends_on\": subquestion.depends_on,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Shows the result from the fetched tools for each subquestion's query \n",
    "for subq in subquestions_and_tools:\n",
    "    print(f\"{subq['id']} - {subq['subquestion']}\")\n",
    "    print(f\"  Query: {subq['query']}\")\n",
    "    if subquestion.depends_on:\n",
    "        print(f\"  Depends on: {subq['depends_on']}\")\n",
    "    print(\"  Fetched tools:\")\n",
    "    for tool in subq[\"tools\"]:\n",
    "        print(\"    \" + tool.name + \": \" + tool.description.split('\\n')[0])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent to execute on each subquestion\n",
    "\n",
    "The ReAct agent answers each of the subquestions. This is done by providing it with the subquestion and it's corresponding fetched tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_react_agent(tools):\n",
    "    \"Define a ReAct agent bound with specific tools.\"\n",
    "    # This retrieves a good chat prompt template available in Langchain Hub\n",
    "    # https://smith.langchain.com/hub/hwchase17/react-json?organizationId=10beea65-e722-5aa1-9f93-034c22e3cd6e\n",
    "    prompt = hub.pull(\"hwchase17/react-multi-input-json\")\n",
    "    # Replace the 'tools' and 'tool_names' content of the prompt with information given to the agent\n",
    "    # Note that tool_names is a field available in each tool, so it can be inferred from same argument\n",
    "    prompt = prompt.partial(\n",
    "        tools=render_text_description_and_args(tools),\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "    )\n",
    "\n",
    "    # LLM to be used\n",
    "    llm = ChatOpenAI(model=\"gpt-4-1106-preview\").bind(stop=[\"\\nObservation\"])\n",
    "\n",
    "    # Create agent chain\n",
    "    chain = (\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | JSONAgentOutputParser()\n",
    "    )\n",
    "\n",
    "    # Agent executing with access to the chain and tools at its disposal\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        tools=tools,\n",
    "        verbose=False,  # <-- set this to False to cut down on output spam. But it's useful for debugging!\n",
    "        return_intermediate_steps=False,\n",
    "        handle_parsing_errors=True,\n",
    "    )\n",
    "    return agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are the peers of Tesla (TSLA)?\n",
      "- Tesla's peers include a range of companies in the electric vehicle and broader automotive sector. Based on the provided data, Tesla's peers are:\n",
      "- XPeng Inc. (XPEV)\n",
      "- Li Auto Inc. (LI)\n",
      "- Rivian Automotive, Inc. (RIVN)\n",
      "- Lucid Group, Inc. (LCID)\n",
      "- General Motors Company (GM)\n",
      "- NIO Inc. (NIO)\n",
      "- Ford Motor Company (F)\n",
      "- Fisker Inc. (FSR)\n",
      "- Mullen Automotive, Inc. (MULN)\n",
      "\n",
      "\n",
      "Which of Tesla's peers has the highest market cap?\n",
      "- Tesla's peers include a range of companies in the electric vehicle and broader automotive sector.\n",
      "- Based on market capitalization data retrieved from the tools provided, the peer with the highest market cap is General Motors Company (GM) with a market capitalization of $43,275,565,978.\n",
      "\n",
      "\n",
      "What is the most recent price target estimate for the company with the highest market cap?\n",
      "- The most recent price target estimate for General Motors Company (GM), which has the highest market cap among Tesla's peers, is $37.0.\n",
      "- This estimate was provided by Dan Levy from Barclays on November 1, 2023.\n",
      "\n",
      "\n",
      "Who made the most recent price target estimate for the company with the highest market cap?\n",
      "- The most recent price target estimate was made by Dan Levy from Barclays.\n",
      "- The estimate was provided on November 1, 2023.\n",
      "\n",
      "\n",
      "On what date was the most recent price target estimate for the company with the highest market cap made?\n",
      "- The most recent price target estimate for the company with the highest market cap among TSLA's peers was made on November 1, 2023.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "# Go through each subquestion and create an agent to execute on it\n",
    "for i, subquestion in enumerate(subquestions_and_tools):\n",
    "\n",
    "    # We handle each dependency manually since we don't want agents to share memory as this can go over context length\n",
    "    deps = [dep for dep in subquestions_and_tools if dep[\"id\"] in subquestion[\"depends_on\"]]\n",
    "\n",
    "    dependencies = \"\"\n",
    "    for dep in deps:\n",
    "        dependencies += \"subquestion: \" + dep[\"subquestion\"] + \"\\n\"\n",
    "        # if for some reason there's no temporal dependency between the agents being run\n",
    "        # this ensures the code doesn't break here\n",
    "        if \"observation\" in dep:\n",
    "            dependencies += \"observations:\\n\" + str(dep[\"observation\"]) + \"\\n\\n\"\n",
    "\n",
    "    input = f\"\"\"\\\n",
    "Given the following high-level question: {PROMPT}\n",
    "Answer the following subquestion: {subquestion['subquestion']}\n",
    "\n",
    "Give your answer in a bullet-point list.\n",
    "Explain your reasoning, and make reference to and provide the relevant retrieved data as part of your answer.\n",
    "\n",
    "Remember to use the tools provided to you to answer the question, and STICK TO THE INPUT SCHEMA.\n",
    "\n",
    "Example output format:\n",
    "```\n",
    "- <the first observation, insight, and/or conclusion> \n",
    "- <the second observation, insight, and/or conclusion> \n",
    "- <the third observation, insight, and/or conclusion> \n",
    "... REPEAT AS MANY TIMES AS NECESSARY TO ANSWER THE SUBQUESTION.\n",
    "```\n",
    "\n",
    "If necessary, make use of the following subquestions and their answers to answer your subquestion:\n",
    "{dependencies}\n",
    "\n",
    "Return only your answer as a bulleted list as a single string. Don't respond with JSON or any other kind of data structure.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = langchain_react_agent(tools=subquestion[\"tools\"]).invoke({\"input\": input})\n",
    "        output = result[\"output\"]\n",
    "    except Exception as err:  # Terrible practice, but it'll do for now.\n",
    "        print(err)\n",
    "        # We'll include the error message in the future\n",
    "        output = \"I was unable to answer the subquestion using the available tool.\" \n",
    "\n",
    "\n",
    "    # This is very cheeky but we are basically going into the subquestions_and_tools and for this current subquestion\n",
    "    # we are adding the output as an observation. This is important because then above we do the dependencies check-up\n",
    "    # which allows us to retrieve the correct output to be used in another subquestion.\n",
    "    # Note: this works because subquestions are done in order to execute prompt. Otherwise it wouldn't since we would\n",
    "    # be looking for an \"observation\" that doesn't exist yet.\n",
    "    subquestion[\"observation\"] = output\n",
    "\n",
    "    print(subquestion['subquestion'])\n",
    "    if isinstance(output, Dict):\n",
    "        for val in output.values():\n",
    "            print(val)\n",
    "    else:\n",
    "        print(output)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verdict\n",
    "\n",
    "To combine all of the subquestion answers to generate a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_subquestions_and_answers(subquestions):\n",
    "    \"Combines all subquestions and their answers\"\n",
    "    output = \"\"\n",
    "    for subquestion in subquestions:\n",
    "        output += \"Subquestion: \" + subquestion[\"subquestion\"] + \"\\n\"\n",
    "        output += \"Observations: \\n\" + str(subquestion[\"observation\"]) + \"\\n\\n\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verdict(question: str, subquestions: Dict):\n",
    "    \"Based on the high-level question, it combines the subquestions and their answers to give one final concise answer\"\n",
    "    system_message = \"\"\"\\\n",
    "        Given the following high-level question: \n",
    "    \n",
    "        {input}\n",
    "    \n",
    "        And the following subquestions and subsequent observations:\n",
    "    \n",
    "        {subquestions}\n",
    "    \n",
    "        Answer the high-level question. Give your answer in a bulleted list.\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system_message)])\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4\")  # Let's use the big model for the final answer.\n",
    "    \n",
    "    final_chain = (\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"subquestions\": lambda x: render_subquestions_and_answers(x[\"subquestions\"]),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "    )\n",
    "    \n",
    "    result = final_chain.invoke({\"input\": question, \"subquestions\": subquestions})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tesla's peers include XPeng Inc. (XPEV), Li Auto Inc. (LI), Rivian Automotive, Inc. (RIVN), Lucid Group, Inc. (LCID), General Motors Company (GM), NIO Inc. (NIO), Ford Motor Company (F), Fisker Inc. (FSR), and Mullen Automotive, Inc. (MULN).\n",
      "- The peer with the highest market cap is General Motors Company (GM), with a market capitalization of $43,275,565,978.\n",
      "- The most recent price target estimate for General Motors Company (GM) is $37.0.\n",
      "- This estimate was provided by Dan Levy from Barclays.\n",
      "- The estimate was provided on November 1, 2023.\n"
     ]
    }
   ],
   "source": [
    "result = verdict(\n",
    "    question=PROMPT,\n",
    "    subquestions=subquestions_and_tools\n",
    ")\n",
    "print(result.content)  # Et voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symbol</td>\n",
       "      <td>GM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price</td>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beta</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vol_avg</td>\n",
       "      <td>15356006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mkt_cap</td>\n",
       "      <td>43275565978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0            1\n",
       "0   symbol           GM\n",
       "1    price         31.6\n",
       "2     beta         1.49\n",
       "3  vol_avg     15356006\n",
       "4  mkt_cap  43275565978"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obb.equity.fundamental.overview(\"GM\").to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>published_date</th>\n",
       "      <th>news_url</th>\n",
       "      <th>news_title</th>\n",
       "      <th>analyst_name</th>\n",
       "      <th>analyst_company</th>\n",
       "      <th>price_target</th>\n",
       "      <th>adj_price_target</th>\n",
       "      <th>price_when_posted</th>\n",
       "      <th>news_publisher</th>\n",
       "      <th>news_base_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GM</td>\n",
       "      <td>2023-11-01 02:32:00</td>\n",
       "      <td>https://www.streetinsider.com/Upgrades/Barclay...</td>\n",
       "      <td>Barclays Upgrades General Motors (GM) to Overw...</td>\n",
       "      <td>Dan Levy</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>StreetInsider</td>\n",
       "      <td>streetinsider.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol      published_date  \\\n",
       "0     GM 2023-11-01 02:32:00   \n",
       "\n",
       "                                            news_url  \\\n",
       "0  https://www.streetinsider.com/Upgrades/Barclay...   \n",
       "\n",
       "                                          news_title analyst_name  \\\n",
       "0  Barclays Upgrades General Motors (GM) to Overw...     Dan Levy   \n",
       "\n",
       "  analyst_company  price_target  adj_price_target  price_when_posted  \\\n",
       "0        Barclays          37.0              37.0               28.2   \n",
       "\n",
       "  news_publisher      news_base_url  \n",
       "0  StreetInsider  streetinsider.com  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obb.equity.estimates.price_target(\"GM\").to_df().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
