{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenBB Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies, in specific langchain\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import hub\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"  # Avoid some warnings from HuggingFace\n",
    "\n",
    "# Set up OpenAI API key\n",
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = \"\n",
    "\n",
    "# Set up OpenBB Personal Access Token from https://my.openbb.co/app/platform/pat\n",
    "from openbb import obb\n",
    "from utils import map_openbb_collection_to_langchain_tools  # provides access to OpenBB Tools\n",
    "obb.account.login(pat=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OpenBB tool retrieval\n",
    "\n",
    "The following will return all OpenBB tools that we want our agent to have access. This matches the layout architecture defined by OpenBB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openbb_tools = map_openbb_collection_to_langchain_tools(\n",
    "    [\"/equity/fundamental\", \"/equity/compare\", \"/equity/estimates\"] # can also give a single string\n",
    ")\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=t.description, metadata={\"index\": i})\n",
    "    for i, t in enumerate(openbb_tools)\n",
    "]\n",
    "print(len(docs))\n",
    "\n",
    "# Emperically, these Sentence embeddings can occasionally be better.\n",
    "# (But it is a substantially heavier dependency than relying on OpenAI's API.)\n",
    "# sentence_transformer = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# vector_store = FAISS.from_documents(docs, sentence_transformer)\n",
    "vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})  # <- now returns top 2\n",
    "\n",
    "def get_tools(query):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return [openbb_tools[d.metadata[\"index\"]] for d in docs]\n",
    "\n",
    "# Quick test\n",
    "fetched_tools = get_tools(\"analyst price\")\n",
    "for tool in fetched_tools:\n",
    "    print(\"tool: \" + tool.name + \", description: \" + tool.description.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make it easy to create react agents since we'll need a lot of them later.\n",
    "from langchain.output_parsers import RetryWithErrorOutputParser\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "retry_parser = RetryWithErrorOutputParser.from_llm(\n",
    "    parser=JSONAgentOutputParser(), llm=OpenAI(temperature=0, model=\"gpt-4\")\n",
    ")\n",
    "\n",
    "def langchain_react_agent(tools):\n",
    "    \"\"\"Define a ReAct agent bound with specific tools.\"\"\"\n",
    "    prompt = hub.pull(\"hwchase17/react-multi-input-json\")\n",
    "    prompt = prompt.partial(\n",
    "        tools=render_text_description_and_args(tools),\n",
    "        tool_names=\", \".join([t.name for t in tools]),\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4-1106-preview\").bind(stop=[\"\\nObservation\"])\n",
    "\n",
    "    chain = (\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | JSONAgentOutputParser()\n",
    "    )\n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        tools=tools,\n",
    "        verbose=True,  # <-- set this to False to cut down on output spam. But it's useful for debugging!\n",
    "        return_intermediate_steps=False,\n",
    "        handle_parsing_errors=True,\n",
    "    )\n",
    "    return agent_executor\n",
    "\n",
    "agent_executor = langchain_react_agent(tools=fetched_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary goal is to\n",
    "# 1. Break a larger question down into subquestions + the appropriate query to fetch the right tool to answer the subquestion\n",
    "# 2. Retrieve the right tools for each subquestion\n",
    "# 3. Answer each subquestion using a ReAct agent\n",
    "# 4. To combine all of the subquestion answers to generate a final answer.\n",
    "\n",
    "# Part 1 break it into subquestions\n",
    "\n",
    "\n",
    "# We'll use Pydantic to do some output enforcement\n",
    "# (It's just prompting and parsing under the hood)\n",
    "class SubQuestion(BaseModel):\n",
    "    id: int = Field(description=\"The unique ID of the subquestion.\")\n",
    "    question: str = Field(description=\"The subquestion itself.\")\n",
    "    query: str = Field(\n",
    "        description=\"The query to pass to the `fetch_tools` function to retrieve the appropriate tool to answer the question.\"\n",
    "    )\n",
    "    depends_on: list[int] = Field(description=\"The list of subquestion ids whose answer is required to answer this subquestion.\", default=[])\n",
    "\n",
    "class SubQuestionList(BaseModel):\n",
    "    subquestions: list[SubQuestion] = Field(\n",
    "        description=\"The list of SubQuestion objects.\"\n",
    "    )\n",
    "\n",
    "subquestion_parser = PydanticOutputParser(pydantic_object=SubQuestionList)\n",
    "\n",
    "system_message = \"\"\"\\\n",
    "You are a world-class state-of-the-art agent.\n",
    "\n",
    "You can access multiple tools, via a \"fetch_tools\" function that will retrieve the necessary tools.\n",
    "The `fetch_tools` function accepts a string of keywords as input specifying the type of tool to retrieve.\n",
    "Each retrieved tool represents a different data source or API that can retrieve the required data.\n",
    "\n",
    "Your purpose is to help answer a complex user question by generating a list of sub\n",
    "questions, as well as the corresponding keyword query to the \"fetch_tools\" function\n",
    "to retrieve the relevant tools to answer each corresponding subquestion.\n",
    "You must also specify the dependencies between subquestions, since sometimes one\n",
    "subqueston will require the outcome of another in order to fully answer.\n",
    "\n",
    "These are the guidelines you consider when completing your task:\n",
    "* Be as specific as possible\n",
    "* Avoid using acronyms\n",
    "* The sub-questions should be relevant to the user question\n",
    "* The sub-questions should be answerable by the tools retrieved by the query to `fetch_tools`\n",
    "* You can generate multiple sub-questions\n",
    "* You don't need to query for a tool if you don't think it's relevant\n",
    "* A subquestion may not depend on a subquestion that proceeds it (i.e. comes after it.)\n",
    "\n",
    "## Output format\n",
    "{format_instructions}\n",
    "\n",
    "### Example responses\n",
    "```json\n",
    "{{\"subquestions\": [\n",
    "    {{\n",
    "        \"id\": 1,\n",
    "        \"question\": \"What are the latest financial statements of AMZN?\", \n",
    "        \"query\": \"financial statements\",\n",
    "        \"depends_on\": []\n",
    "    }}, \n",
    "    {{\n",
    "        \"id\": 2,\n",
    "        \"question\": \"What is the most recent revenue and profit margin of AMZN?\", \n",
    "        \"query\": \"revenue profit margin ratios\",\n",
    "        \"depends_on\": []\n",
    "    }}, \n",
    "    {{\n",
    "        \"id\": 3,\n",
    "        \"question\": \"What is the current price to earnings (P/E) ratio of AMZN?\", \n",
    "        \"query\": \"ratio price to earnings\",\n",
    "        \"depends_on\": []\n",
    "    }}, \n",
    "    {{\n",
    "        \"id\": 4,\n",
    "        \"question\": \"Who are the peers of AMZN?\", \n",
    "        \"query\": \"peers\",\n",
    "        \"depends_on\": []\n",
    "    }},\n",
    "    {{\n",
    "        \"id\": 5,\n",
    "        \"question\": \"Which of AMZN's peers have the largest market cap?\", \n",
    "        \"query\": \"market cap\",\n",
    "        \"depends_on\": [4]\n",
    "    }}\n",
    "]}}\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "human_message = \"\"\"\\\n",
    "    ## User Question\n",
    "    {input}\n",
    "    \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", human_message),\n",
    "    ]\n",
    ")\n",
    "prompt = prompt.partial(\n",
    "    format_instructions=subquestion_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\"\n",
    ")  # gpt-3.5-turbo works well, but gpt-4-1106-preview isn't good at returning JSON.\n",
    "\n",
    "subquestion_chain = {\"input\": lambda x: x[\"input\"]} | prompt | llm | subquestion_parser\n",
    "\n",
    "# Our high-level question we're going to attempt to answer\n",
    "INPUT =  \"\"\"\\\n",
    "Check what are TSLA peers. From those, check which one has the highest market cap.\n",
    "Then, on the ticker that has the highest market cap get the most recent price target estimate from an analyst,\n",
    "and tell me who it was and one what date the estimate was made.\n",
    "\"\"\"\n",
    "\n",
    "# INPUT = \"Perform a fundamentals financial analysis of AMZN using the most recently available data. What do you find that's interesting?\"\n",
    "\n",
    "subquestion_list = subquestion_chain.invoke({\"input\": INPUT})\n",
    "\n",
    "for subquestion in subquestion_list.subquestions:\n",
    "    print(\n",
    "        subquestion\n",
    "    )  # We probably won't have all the right tools to answer these questions. Improvements for the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 is to fetch the appropriate tool for each subquestion\n",
    "# (We'll create a new data structure here we can re-use)\n",
    "\n",
    "subquestions_and_tools = []\n",
    "\n",
    "for subquestion in subquestion_list.subquestions:\n",
    "    tools = get_tools(subquestion.query)\n",
    "    subquestions_and_tools.append(\n",
    "        {   \"id\": subquestion.id,\n",
    "            \"subquestion\": subquestion.question,\n",
    "            \"query\": subquestion.query,\n",
    "            \"tools\": tools,\n",
    "            \"depends_on\": subquestion.depends_on,\n",
    "        }\n",
    "    )\n",
    "\n",
    "for subq in subquestions_and_tools:\n",
    "    print(\"id: \", subq[\"id\"])\n",
    "    print(\"subquestion \", subq[\"subquestion\"])\n",
    "    print(\"query: \", subq[\"query\"])\n",
    "    print(\"depends on: \", subq[\"depends_on\"])\n",
    "    for tool in subq[\"tools\"]:\n",
    "        print(\"  \" + tool.name + \": \" + tool.description.split('\\n')[0])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 is to answer each of the subqueries. We'll use a ReAct agent paired with the subquestion and appropriate tools to do this.\n",
    "\n",
    "agents = []\n",
    "for i, subquestion in enumerate(subquestions_and_tools):\n",
    "    react_agent = langchain_react_agent(tools=subquestion[\"tools\"])\n",
    "    agents.append(react_agent)\n",
    "\n",
    "len(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agents to answer the subquestions\n",
    "for i, subquestion in enumerate(subquestions_and_tools):\n",
    "    deps = [dep for dep in subquestions_and_tools if dep[\"id\"] in subquestion[\"depends_on\"]]\n",
    "\n",
    "    dependencies = \"\"\n",
    "    for dep in deps:\n",
    "        dependencies += \"subquestion: \" + dep[\"subquestion\"] + \"\\n\"\n",
    "        dependencies += \"observations:\\n\" + str(dep[\"observation\"]) + \"\\n\\n\"\n",
    "\n",
    "\n",
    "    input = f\"\"\"\\\n",
    "Given the following high-level question: {INPUT}\n",
    "Answer only the following subquestion: {subquestion['subquestion']}\n",
    "\n",
    "Give your answer in a bullet-point list.\n",
    "Explain your reasoning, and make reference to and provide the relevant retrieved data as part of your answer.\n",
    "\n",
    "Remember to use the tools provided to you to answer the question, and STICK TO THE INPUT SCHEMA.\n",
    "\n",
    "Example output format:\n",
    "```\n",
    "- <the first observation, insight, and/or conclusion> \n",
    "- <the second observation, insight, and/or conclusion> \n",
    "- <the third observation, insight, and/or conclusion> \n",
    "... REPEAT AS MANY TIMES AS NECESSARY TO ANSWER THE SUBQUESTION.\n",
    "```\n",
    "If necessary, make use of the following subquestions and their answers was to answer your subquestion:\n",
    "{dependencies}\n",
    "\n",
    "Return only your answer as a bulleted list as a single string. Don't respond with JSON or any other kind of datastructure.\n",
    "\"\"\"\n",
    "\n",
    "    print(\"=======QUESTION + PROMPT========\")\n",
    "    print(input)\n",
    "\n",
    "\n",
    "    result = agents[i].invoke({\"input\": input})\n",
    "    output = result[\"output\"]\n",
    "\n",
    "    try:\n",
    "        result = agents[i].invoke({\"input\": input})\n",
    "        output = result[\"output\"]\n",
    "    except Exception as err:  # Terrible practice, but it'll do for now.\n",
    "        print(err)\n",
    "        output = \"I was unable to answer the subquestion using the available tool.\"  # We'll include the error message in the future\n",
    "\n",
    "    # print(subquestion[\"subquestion\"])\n",
    "    # print(\"----\")\n",
    "    # print(output)\n",
    "    # print(\"=======\")\n",
    "\n",
    "    # We'll misbehave and re-use the same datastructure again\n",
    "    subquestion[\"observation\"] = output\n",
    "    print(\"=======ANSWER========\")\n",
    "    print(output)\n",
    "    print(\"=====================\")\n",
    "    print(\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4 is to generate a response based on the answers to each of the subquestions\n",
    "\n",
    "def render_subquestions_and_answers(subquestions):\n",
    "    output = \"\"\n",
    "    for subquestion in subquestions:\n",
    "        output += \"Subquestion: \" + subquestion[\"subquestion\"] + \"\\n\"\n",
    "        output += \"Observations: \\n\" + str(subquestion[\"observation\"]) + \"\\n\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "system_message = \"\"\"\\\n",
    "    Given the following high-level question: \n",
    "\n",
    "    Question: {input}\n",
    "\n",
    "    And the following subquestions and subsequent observations:\n",
    "\n",
    "    {subquestions}\n",
    "\n",
    "    Answer the high-level question. Give your answer in a bulleted list.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system_message)])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\")  # Let's use the big model for the final answer.\n",
    "\n",
    "final_chain = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"subquestions\": lambda x: render_subquestions_and_answers(x[\"subquestions\"]),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = final_chain.invoke({\"input\": INPUT, \"subquestions\": subquestions_and_tools})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openbb import obb\n",
    "obb.equity.estimates.price_target(\"F\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)  # Et voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
